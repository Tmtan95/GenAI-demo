# RAG System Setup Instructions

## ğŸ“š **Recommended Embedding Model**

**ğŸ¥‡ BAAI/bge-large-en-v1.5**
- **Size**: ~1.34GB (high-quality model)
- **Dimensions**: 1024 (excellent for semantic understanding)
- **Performance**: State-of-the-art accuracy for technical documents
- **Speed**: Optimized for large PDFs (15MB+)
- **Offline**: Works completely offline after initial download
- **Best for**: Research papers, technical documentation, large documents

## ğŸ› ï¸ **Installation**

1. **Install RAG dependencies:**
```bash
# Activate your virtual environment first
source env/bin/activate  # On macOS/Linux

# Install all required packages
pip install -r requirements.txt
```

2. **Add your PDF documents:**
```bash
# Place 2-3 PDF files in the documents folder
cp your_document1.pdf documents/
cp your_document2.pdf documents/
cp your_document3.pdf documents/
```

3. **Test the system:**
```bash
# Run the main demo
python app/demo.py

# Select option 2 (Document Analysis)
```

## ğŸ¯ **RAG System Features**

### **Smart Caching**
- âœ… Processes documents once, caches results
- âš¡ Lightning-fast subsequent loads
- ğŸ”„ Auto-detects document changes

### **Optimized for Large Documents**
- ğŸ“Š Chunk size: 500 characters (optimal for PDFs)
- ğŸ¯ Retrieves top 3 most relevant sections
- ï¿½ Handles 15MB+ PDF files efficiently
- ğŸ“ High-quality embeddings for better semantic search

### **Offline Operation**
- ğŸ”’ No internet required after setup
- ğŸ›¡ï¸ Your documents stay private
- âš¡ Fast local inference

## ğŸ“‹ **Usage Example**

1. **Start the application:**
```bash
python app/demo.py
```

2. **Select Document Analysis (Option 2)**

3. **Ask questions like:**
- "What are the main topics covered in these documents?"
- "Summarize the key findings"
- "What recommendations are made?"
- "Explain the methodology used"

## ğŸ—‚ï¸ **Project Structure**
```
GenAI-Demo/
â”œâ”€â”€ documents/           # Place your PDF files here
â”œâ”€â”€ cache/              # Cached embeddings (auto-generated)
â”œâ”€â”€ rag_system.py       # RAG implementation
â”œâ”€â”€ app/demo.py         # Main application
â””â”€â”€ requirements.txt    # Dependencies
```

## ğŸ”§ **Troubleshooting**

### **"No PDF files found"**
- Make sure PDFs are in the `documents/` folder
- Check file extensions are `.pdf` (lowercase)

### **Import errors**
```bash
# Install missing packages
pip install sentence-transformers faiss-cpu PyPDF2 numpy
```

### **Memory issues**
- The system is optimized for small files (2-3 PDFs)
- If you have large PDFs, consider splitting them

### **Embedding model download**
- First run downloads ~23MB model
- Subsequent runs use cached model
- No internet needed after first setup

## ğŸš€ **Performance Tips**

1. **PDF Quality**: Clear, text-based PDFs work best
2. **File Size**: Keep individual PDFs under 10MB for best performance  
3. **Document Count**: Optimal with 2-3 PDFs (as requested)
4. **Questions**: Be specific for better retrieval results

## ğŸ¨ **Advanced Features**

- **Similarity Scoring**: Shows relevance of retrieved content
- **Source Attribution**: Links answers back to specific documents
- **Context Chunking**: Smart text segmentation with overlap
- **Vector Search**: Fast semantic similarity matching

## ğŸ“Š **Model Specifications**

| Feature | Specification |
|---------|---------------|
| Embedding Model | all-MiniLM-L6-v2 |
| Model Size | ~23MB |
| Embedding Dimensions | 384 |
| Chunk Size | 500 characters |
| Chunk Overlap | 50 characters |
| Top-K Retrieval | 3 chunks |
| Vector Store | FAISS (CPU) |
| PDF Parser | PyPDF2 |

Perfect for your requirements: **small, offline, efficient!** ğŸ¯